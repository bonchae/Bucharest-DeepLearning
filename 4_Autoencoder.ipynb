{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9BguMAidjK/sEBmk3n07d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Autoencoder"],"metadata":{"id":"tYLL5lHp-uq1"}},{"cell_type":"markdown","source":["Autoencoders learn how to compress and decompress complex data like images. This is conceptually similar to PCA-based dimensionality reduction, but autoencoders can capture nonlinear patterns, whereas PCA is limited to linear relationships.\n","\n","This is an example of **unsupervised** DL."],"metadata":{"id":"Lni7kW6c-w8t"}},{"cell_type":"markdown","source":["<img src=\"https://contenthub-static.grammarly.com/blog/wp-content/uploads/2024/10/6303_blog-visuals-auto-encoders_1500X800.png\" width=800>\n","\n","The Autoencoder structure shows:\n","\n","- **Input Data** ➔ **Encoder Layers** ➔ **Latent Space (Bottleneck)** ➔ **Decoder Layers** ➔ **Reconstructed Data**"],"metadata":{"id":"8KoWW3ny9a6c"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Yxn6LYX1-t6w"}},{"cell_type":"markdown","source":["| Part | Diagram Description | Code (Implementation) |\n","|:---|:---|:---|\n","| **Input Layer** | Green nodes on the left (Input Data) | `Input(shape=(4096,))` |\n","| **Encoder Layers** | Left side layers compressing the input | `Dense(512, relu)`, `Dense(128, relu)` |\n","| **Bottleneck (Latent Space)** | Red nodes (smallest point) | `Dense(128)` |\n","| **Decoder Layers** | Right side layers expanding back | `Dense(512, relu)`, `Dense(4096, sigmoid)` |\n","| **Output Layer** | Final reconstructed output | `Model(input_img, decoded)` |\n","\n","\n","---\n","\n","\n","- The **Encoder** compresses a 4096-dimensional input (64×64 face image) into a **128-dimensional feature vector**.\n","- The **Bottleneck** is the compressed representation that holds essential information about the face.\n","- The **Decoder** expands the 128 features back to reconstruct the original 4096 features.\n","- The model is trained to **minimize the difference** between the input and reconstructed output.\n"],"metadata":{"id":"It0qh57g-SBx"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_olivetti_faces\n","import tensorflow as tf\n","from tensorflow.keras import layers, models"],"metadata":{"id":"_VXlMSnp_kzU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Olivetti Faces Dataset\n","faces_data = fetch_olivetti_faces(shuffle=True, random_state=42)\n","faces = faces_data.data  # shape: (400, 4096)\n","targets = faces_data.target  # not used here"],"metadata":{"id":"5B5Dai4M_k2h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In datasets like MNIST or Olivetti Faces (after normalization), pixel values are floating numbers from 0 to 1"],"metadata":{"id":"fduRY-vsB4SU"}},{"cell_type":"code","source":["print(f\"Faces shape: {faces.shape}\")  # 400 images, each 64x64 (flattened to 4096)"],"metadata":{"id":"l_dQ5R9N_k6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a DataFrame with the face data\n","\n","# First, create a DataFrame with the pixel values\n","pixel_columns = [f'pixel_{i}' for i in range(faces.shape[1])]\n","faces_df = pd.DataFrame(faces, columns=pixel_columns)\n","\n","# Add the target (person identifier) as a column\n","faces_df['person_id'] = targets\n","\n","print(\"First 5 rows of the DataFrame:\")\n","faces_df.head()"],"metadata":{"id":"DwX1giE2CBjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split into train and test\n","from sklearn.model_selection import train_test_split\n","x_train, x_test = train_test_split(faces, test_size=0.2, random_state=42)"],"metadata":{"id":"qrnpySZc_k9k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Step 1: Define the architecture (Autoencoder)"],"metadata":{"id":"KHNoptKUADmM"}},{"cell_type":"code","source":["# Input Layer: 4096 neurons, representing the 64x64 face images flattened into a vector\n","input_img = tf.keras.Input(shape=(faces.shape[1],))\n","\n","# Encoder Part:\n","# First hidden layer with 512 neurons and ReLU activation\n","encoded = layers.Dense(512, activation='relu')(input_img)\n","\n","# Second hidden layer with 128 neurons (bottleneck/latent space), compressing features further\n","encoded = layers.Dense(256, activation='relu')(encoded)\n","\n","# Decoder Part:\n","# First decoding layer expands back to 512 neurons with ReLU activation\n","decoded = layers.Dense(512, activation='relu')(encoded)\n","\n","# Output layer: reconstructs the original 4096-dimensional image using sigmoid activation\n","decoded = layers.Dense(4096, activation='sigmoid')(decoded)\n","\n","# Define the complete Autoencoder model connecting input to reconstructed output\n","autoencoder = models.Model(input_img, decoded)"],"metadata":{"id":"-w44IuM3AC4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model with Adam optimizer and binary cross-entropy loss\n","autoencoder.compile(optimizer='adam',\n","                    loss='mse')"],"metadata":{"id":"Lncu877oAC7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Autoencoder\n","autoencoder.fit(x_train, x_train,\n","                epochs=50,\n","                batch_size=32,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))"],"metadata":{"id":"_7OiODuMAC-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reconstruct faces\n","decoded_faces = autoencoder.predict(x_test)"],"metadata":{"id":"D4VbXae7CygY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot first 12 Original and Reconstructed faces\n","n = 12\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    # Original\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.imshow(x_test[i].reshape(64, 64), cmap='gray')\n","    plt.title(\"Original\")\n","    plt.axis('off')\n","\n","    # Reconstructed\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(decoded_faces[i].reshape(64, 64), cmap='gray')\n","    plt.title(\"Reconstructed\")\n","    plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"gBe3sVLEADEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["| PCA | Autoencoder |\n","|:---|:---|\n","| Very strong for linear patterns | Can capture nonlinear patterns (but needs tuning!) |\n","| May outperform basic autoencoder on structured datasets | Needs better architecture + training to shine |\n","| No training time | Requires training and optimization |\n"],"metadata":{"id":"x0SxAkjSWa09"}}]}